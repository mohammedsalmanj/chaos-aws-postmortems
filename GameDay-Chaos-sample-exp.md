üéÆ GameDay / Chaos Lab: Simulating the AWS DNS Outage
üéØ Objective

Re-create a DNS resolution failure similar to the Oct 2025 AWS US-East incident,
observe how applications behave when they can‚Äôt reach a dependency,
and practice restoring service without causing additional damage.

üß± Lab Setup

Choose one of two environments:

Option	Environment	Tools Used
A. Local (Docker)	Simple micro-service app + internal DNS container	Docker Compose, CoreDNS, New Relic Agent
B. AWS Sandbox	EC2 + Route 53 Private Hosted Zone	AWS FIS ( Fault Injection Simulator ), CloudWatch, X-Ray, New Relic

Both options follow the same flow:
1Ô∏è‚É£ Run a healthy app ‚Üí 2Ô∏è‚É£ Break DNS ‚Üí 3Ô∏è‚É£ Observe metrics ‚Üí 4Ô∏è‚É£ Recover ‚Üí 5Ô∏è‚É£ Review alerts.

‚öôÔ∏è Step 1 ‚Äî Normal Operation (Baseline)

Application:
A tiny Python or Node.js web app calling DynamoDB (or a mock DB API).

curl http://app.local/ping-db
# ‚Üí 200 OK  (DB reachable)


Verify Metrics:

CloudWatch ‚Üí DNSResolutionTime ~ few ms

New Relic ‚Üí Green dependency graph

X-Ray ‚Üí Full trace reaching DB endpoint

üí• Step 2 ‚Äî Inject DNS Failure
üî∏ Local Option

Simulate broken resolver:

# Stop DNS resolver in app container
docker exec app bash -c "echo 'nameserver 127.0.0.2' > /etc/resolv.conf"
curl http://app.local/ping-db
# ‚Üí Could not resolve host

üî∏ AWS Option (FIS)

Create an FIS experiment that blocks outbound 53 traffic:

{
  "description": "Simulate DNS outage by blocking port 53",
  "targets": { "Instances": { "resourceType": "aws:ec2:instance",
    "resourceTags": { "ChaosTarget": "true" }, "selectionMode": "COUNT(1)" } },
  "actions": {
    "BlockDNS": {
      "actionId": "aws:ssm:send-command",
      "parameters": {
        "documentName": "AWSFIS-RunShellScript",
        "documentParameters": { "commands": ["iptables -A OUTPUT -p udp --dport 53 -j DROP"] }
      },
      "targets": { "Instances": "Instances" }
    }
  },
  "roleArn": "arn:aws:iam::<ACCOUNT_ID>:role/FISExperimentRole",
  "stopConditions": [{ "source": "none" }]
}


Run it:

aws fis start-experiment --experiment-template-id <template_id>

üîç Step 3 ‚Äî Observe Impact
Layer	Expected Signal	Analogy
App Logs	Temporary failure in name resolution	App forgot everyone‚Äôs phone number
CloudWatch	Route 53 errors ‚Üë , HTTP 5xx ‚Üë	Calls failing before leaving app
New Relic APM	Red dependency line to DB	Broken link on service map
X-Ray	Trace halts at DNS segment	Conversation ends mid-sentence

üß© Analogy: The app keeps trying to call the database, but its ‚Äúcontact list‚Äù vanished ‚Äî it just keeps redialing the void.

üß∞ Step 4 ‚Äî Recover and Validate

Local Recovery

docker exec app bash -c "echo 'nameserver 8.8.8.8' > /etc/resolv.conf"


AWS Recovery

aws ssm send-command \
--targets "Key=tag:ChaosTarget,Values=true" \
--document-name "AWS-RunShellScript" \
--parameters '{"commands":["iptables -F"]}'


Validate

curl http://app.local/ping-db
# ‚Üí 200 OK


Metrics should return to baseline; ALB health checks turn green.

üìà Step 5 ‚Äî Review and Debrief
Question	Discussion Point
Detection Time	How quickly did alerts fire?
Alert Context	Did you know it was DNS, or just ‚ÄúDB unreachable‚Äù?
Automation Behavior	Did autoscaling or retries make it worse?
Recovery Speed	How long to restore connectivity?
Communication	Who got notified first ‚Äî infra or app team?

Record outcomes in your postmortem notes folder:
/postmortems/dns-outage-gameday-YYYYMMDD.md

üß† Learning Outcomes
Theme	Takeaway
Dependency Awareness	Apps fail not because of logic, but missing names.
Monitoring	Correlate DNS failures ‚Üî app errors.
Automation	Build ‚Äúpause and inspect‚Äù into health checks.
Resilience	Use cached resolvers / fallback endpoints.

üí¨ Analogy:
Practicing this GameDay is like doing fire drills for your cloud ‚Äî
everyone knows the exits before the smoke shows up.